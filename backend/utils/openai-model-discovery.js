/**
 * OpenAI Model Discovery Tool
 * 
 * This script queries the OpenAI API to discover all available models
 * and generates or updates the openai-models.js configuration file.
 */

const fs = require('fs');
const path = require('path');
const OpenAI = require('openai');
const dotenv = require('dotenv');

dotenv.config();

// Load existing model configuration if available
let existingConfig = { compatibleModels: [], modelConfig: {} };
const configPath = path.join(__dirname, '..', 'config', 'openai-models.js');
if (fs.existsSync(configPath)) {
  try {
    existingConfig = require('../config/openai-models');
    console.log(`Loaded existing configuration with ${existingConfig.compatibleModels.length} models`);
  } catch (error) {
    console.warn('Could not load existing configuration:', error.message);
  }
}

/**
 * Categorize a model based on its name
 * @param {string} modelName - The model name
 * @returns {Object} Model categories and capabilities
 */
function categorizeModel(modelName) {
  const category = {
    best_for: [],
    temperature: 0.7,
    maxTokens: 3000,
    description: 'General purpose model'
  };
  
  // Categorize by model family
  if (modelName.includes('gpt-4o')) {
    category.best_for.push('general', 'complex');
    category.description = 'GPT-4o model for general purpose use';
    
    if (modelName.includes('mini')) {
      category.best_for.push('fast', 'cost-effective');
      category.description = 'GPT-4o Mini - good balance of quality and cost';
    } else {
      category.maxTokens = 4000;
      category.best_for.push('creative');
      category.description = 'GPT-4o - high quality for complex tasks';
    }
  } else if (modelName.includes('o1')) {
    category.best_for.push('complex', 'reasoning');
    category.description = 'O1 model specialized for reasoning tasks';
    
    if (modelName.includes('mini')) {
      category.best_for.push('fast', 'cost-effective');
      category.description = 'O1 Mini - faster, more affordable reasoning model';
    } else {
      category.maxTokens = 4000;
      category.best_for.push('creative');
      category.description = 'O1 - optimized for advanced reasoning';
    }
  } else if (modelName.includes('o3')) {
    category.best_for.push('complex', 'specialized', 'creative');
    category.maxTokens = 4000;
    category.description = 'O3 - advanced multimodal capabilities';
  } else if (modelName.includes('gpt-4')) {
    category.best_for.push('complex', 'comprehensive');
    category.maxTokens = 4000;
    category.description = 'GPT-4 model for complex tasks';
    
    if (modelName.includes('turbo')) {
      category.best_for.push('faster');
      category.description = 'GPT-4 Turbo - improved performance for complex tasks';
    }
  } else if (modelName.includes('gpt-3.5')) {
    category.best_for.push('fast', 'simple', 'cost-effective');
    category.description = 'GPT-3.5 model - fast and affordable';
    
    if (modelName.includes('instruct')) {
      category.best_for.push('focused');
      category.description = 'GPT-3.5 Instruct - optimized for instruction following';
    }
  }
  
  return category;
}

/**
 * Main function to discover and update OpenAI models
 */
async function discoverAndUpdateModels() {
  console.log('Discovering available OpenAI models...');
  
  // Check for API key
  const apiKey = process.env.OPENAI_API_KEY || process.env.OPENAPI_KEY;
  if (!apiKey) {
    console.error('ERROR: OpenAI API key not found. Set OPENAI_API_KEY in .env file');
    process.exit(1);
  }
  
  // Initialize OpenAI client
  const openai = new OpenAI({
    apiKey: apiKey
  });
  
  try {
    // Get all available models
    const response = await openai.models.list();
    const allModels = response.data;
    
    // Filter for chat completion models
    const chatModels = allModels
      .filter(model => 
        model.id.includes('gpt-') || 
        model.id.startsWith('o1-') ||
        model.id.startsWith('o3-')
      )
      .map(model => model.id);
    
    console.log(`Found ${chatModels.length} chat completion models`);
    
    // Create updated configuration
    const updatedModel = {
      compatibleModels: chatModels,
      modelConfig: { ...existingConfig.modelConfig }
    };
    
    // Add new models and categorize them
    for (const modelName of chatModels) {
      if (!existingConfig.modelConfig[modelName]) {
        console.log(`Adding new model: ${modelName}`);
        updatedModel.modelConfig[modelName] = categorizeModel(modelName);
      }
    }
    
    // Generate configuration file content
    const configContent = `/**
 * OpenAI Models Configuration
 * Last updated: ${new Date().toISOString().split('T')[0]}
 * Auto-generated by openai-model-discovery.js
 */

// Compatible OpenAI models for text generation
exports.compatibleModels = [
  ${updatedModel.compatibleModels.map(model => `'${model}'`).join(',\n  ')}
];

// Model-specific configurations
exports.modelConfig = ${JSON.stringify(updatedModel.modelConfig, null, 2)
  .replace(/"([^"]+)":/g, '$1:')
  .replace(/"/g, "'")};

// Helper function to find the best model for a specific task
exports.getBestModelForTask = function(task, preferredModel = null) {
  // If preferred model is specified and valid, use it
  if (preferredModel && exports.compatibleModels.includes(preferredModel)) {
    return preferredModel;
  }
  
  // Otherwise, select best model based on task
  let recommendedModel = 'gpt-4o-mini'; // Default recommendation
  
  // Map tasks to models
  if (task === 'fast' || task === 'cost-effective') {
    recommendedModel = 'gpt-3.5-turbo';
  } else if (task === 'complex' || task === 'creative') {
    recommendedModel = 'gpt-4o';
  } else if (task === 'reasoning') {
    recommendedModel = 'o1-mini';
  }
  
  return recommendedModel;
};

// Get configuration for a specific model
exports.getModelConfig = function(modelName) {
  // If the exact model name doesn't have a config, try to find a match
  // or return a default configuration
  if (!exports.modelConfig[modelName]) {
    // Default configuration
    return {
      maxTokens: 3000,
      temperature: 0.7,
      best_for: ['general'],
      description: 'Unknown model - using default settings'
    };
  }
  
  return exports.modelConfig[modelName];
};`;
    
    // Write configuration to file
    fs.writeFileSync(configPath, configContent, 'utf8');
    console.log(`Updated OpenAI model configuration saved to ${configPath}`);
    console.log(`Total models configured: ${updatedModel.compatibleModels.length}`);
    
    // Update the environment variables if needed
    if (!process.env.OPENAI_MODEL || !updatedModel.compatibleModels.includes(process.env.OPENAI_MODEL)) {
      console.log('Recommended models:');
      console.log('- gpt-4o-mini (best balance of quality and cost)');
      console.log('- gpt-3.5-turbo (fastest, most cost-effective)');
      console.log('- gpt-4o (highest quality)');
      console.log('\nTo set a default model, add to your .env file:');
      console.log('OPENAI_MODEL=gpt-4o-mini');
    }
    
  } catch (error) {
    console.error('Error discovering OpenAI models:', error);
    console.error('API Response:', error.response?.data || 'No response data');
    console.error('Status Code:', error.status || 'Unknown');
    
    // Create a fallback configuration if we couldn't connect to the API
    if (!fs.existsSync(configPath)) {
      console.log('Creating fallback configuration...');
      
      const fallbackConfig = {
        compatibleModels: [
          'gpt-4o',
          'gpt-4o-mini',
          'gpt-3.5-turbo',
          'gpt-4'
        ],
        modelConfig: {
          'gpt-4o': {
            maxTokens: 4000,
            temperature: 0.7,
            best_for: ['general', 'complex', 'creative'],
            description: 'GPT-4o - newest model with strong performance across tasks'
          },
          'gpt-4o-mini': {
            maxTokens: 4000,
            temperature: 0.7,
            best_for: ['general', 'fast', 'cost-effective'],
            description: 'GPT-4o Mini - good balance of quality, speed and cost'
          },
          'gpt-3.5-turbo': {
            maxTokens: 3000,
            temperature: 0.7,
            best_for: ['fast', 'simple', 'cost-effective'],
            description: 'GPT-3.5 Turbo - fast and cost-effective'
          },
          'gpt-4': {
            maxTokens: 4000,
            temperature: 0.7,
            best_for: ['complex', 'precise', 'reasoning'],
            description: 'GPT-4 - strong for complex reasoning tasks'
          }
        }
      };
      
      // Generate fallback configuration file
      const fallbackContent = `/**
 * OpenAI Models Configuration (FALLBACK)
 * Last updated: ${new Date().toISOString().split('T')[0]}
 * This is a fallback configuration created because API discovery failed.
 */

// Compatible OpenAI models for text generation
exports.compatibleModels = [
  ${fallbackConfig.compatibleModels.map(model => `'${model}'`).join(',\n  ')}
];

// Model-specific configurations
exports.modelConfig = ${JSON.stringify(fallbackConfig.modelConfig, null, 2)
  .replace(/"([^"]+)":/g, '$1:')
  .replace(/"/g, "'")};

// Helper function to find the best model for a specific task
exports.getBestModelForTask = function(task, preferredModel = null) {
  // If preferred model is specified and valid, use it
  if (preferredModel && exports.compatibleModels.includes(preferredModel)) {
    return preferredModel;
  }
  
  // Otherwise, select best model based on task
  let recommendedModel = 'gpt-4o-mini'; // Default recommendation
  
  // Map tasks to models
  if (task === 'fast' || task === 'cost-effective') {
    recommendedModel = 'gpt-3.5-turbo';
  } else if (task === 'complex' || task === 'creative') {
    recommendedModel = 'gpt-4o';
  }
  
  return recommendedModel;
};

// Get configuration for a specific model
exports.getModelConfig = function(modelName) {
  // If the exact model name doesn't have a config, try to find a match
  // or return a default configuration
  if (!exports.modelConfig[modelName]) {
    // Default configuration
    return {
      maxTokens: 3000,
      temperature: 0.7,
      best_for: ['general'],
      description: 'Unknown model - using default settings'
    };
  }
  
  return exports.modelConfig[modelName];
};`;
      
      // Write fallback configuration to file
      fs.writeFileSync(configPath, fallbackContent, 'utf8');
      console.log(`Fallback OpenAI model configuration saved to ${configPath}`);
    }
  }
}

// Run the discovery process
discoverAndUpdateModels();